{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNST_CIFAR10_AUG.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/maddy46/mlblr4a_experiments/blob/master/4B_May27_VA84.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "K70hAckqg0EA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wVIx_KIigxPV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UNHw6luQg3gc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cauplz2iYPtZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "5856a0d5-4189-4feb-c656-d9f029d69f52"
      },
      "cell_type": "code",
      "source": [
        "!rm utils.py\n",
        "!wget https://raw.githubusercontent.com/Zahlii/colab-tf-utils/master/utils.py\n",
        "import utils\n",
        "import os\n",
        "import keras\n",
        "\n",
        "def compare(best, new):\n",
        "  return best.losses['val_acc'] < new.losses['val_acc']\n",
        "\n",
        "def path(new):\n",
        "  if new.losses['val_acc'] > 0.2:\n",
        "    return '4B_008_%s.h5' % new.losses['val_acc']\n",
        "\n",
        "callbacks = cb = [\n",
        "      utils.GDriveCheckpointer(compare,path)\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-05-27 10:30:03--  https://raw.githubusercontent.com/Zahlii/colab-tf-utils/master/utils.py\r\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\r\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6935 (6.8K) [text/plain]\n",
            "Saving to: ‘utils.py’\n",
            "\n",
            "utils.py            100%[===================>]   6.77K  --.-KB/s    in 0s      \n",
            "\n",
            "2018-05-27 10:30:03 (61.3 MB/s) - ‘utils.py’ saved [6935/6935]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E-N5JGnk_jVW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 50\n",
        "num_classes = 10\n",
        "epochs =20\n",
        "#l = 40\n",
        "num_filter = 12\n",
        "compression = 0.5\n",
        "dropout_rate = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mB7o3zu1g6eT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c98a6fdc-3c24-4e1c-df0a-a0f1aad99971"
      },
      "cell_type": "code",
      "source": [
        "# Load CIFAR10 Data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "print (img_height)\n",
        "print (img_width)\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UNEhips_IZuH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ea0d7e4e-b450-4f78-9319-fafb66c36422"
      },
      "cell_type": "code",
      "source": [
        "print (x_train.shape[0])\n",
        "print (x_test.shape[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eSJeTVeo_tmf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "0f960132-ecd7-40c2-81f2-4733684d6a6f"
      },
      "cell_type": "code",
      "source": [
        "new_images = np.empty((50000, 24, 24, 3), dtype='uint8')\n",
        "new_test = np.empty((10000, 24, 24, 3), dtype='uint8')\n",
        "\n",
        "for image_count in range(x_train.shape[0]):\n",
        "    new_images[image_count] = cv2.resize(x_train[image_count], (24, 24))\n",
        "for image_count1 in range(x_test.shape[0]):\n",
        "    new_test[image_count1] = cv2.resize(x_test[image_count1], (24, 24))\n",
        "img_height1, img_width1, channel1 = new_images.shape[1],new_images.shape[2],new_images.shape[3]\n",
        "print (img_height1)\n",
        "print (img_width1)\n",
        "\n",
        "print('x Processing Done.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24\n",
            "24\n",
            "x Processing Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TJmHVDzHKZ_n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "ab476937-d3b3-419b-f010-07b29536be07"
      },
      "cell_type": "code",
      "source": [
        "print (new_images.shape)\n",
        "print (y_train.shape)\n",
        "print (new_test.shape)\n",
        "print (y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 24, 24, 3)\n",
            "(50000, 10)\n",
            "(10000, 24, 24, 3)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7BgUOP3gZqnj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(zoom_range=0.2, rotation_range=20)\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ee-sge5Kg7vr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Dense Block\n",
        "def add_denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l):\n",
        "        BatchNorm = BatchNormalization()(temp)\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OOP6IPsGhBwb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def add_transition(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0RaKFpubhDIC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = Flatten()(AvgPooling)\n",
        "    output = Dense(num_classes, activation='softmax')(flat)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "anPCpQWhhGb7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "334ed490-2c5d-4991-9242-eddf426dd356"
      },
      "cell_type": "code",
      "source": [
        "num_filter = 16\n",
        "dropout_rate = 0.2\n",
        "l = 16\n",
        "input = Input(shape=(img_height, img_width, channel,))\n",
        "print(channel)\n",
        "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block = add_denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)\n",
        "#output = output_layer(First_Block)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1kFh7pdxhNtT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 13972
        },
        "outputId": "947e5aad-6d09-4faf-9774-41083c62cc2a"
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_273 (Conv2D)             (None, 32, 32, 16)   432         input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_273 (BatchN (None, 32, 32, 16)   64          conv2d_273[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_273 (Activation)     (None, 32, 32, 16)   0           batch_normalization_273[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_274 (Conv2D)             (None, 32, 32, 8)    1152        activation_273[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_269 (Dropout)           (None, 32, 32, 8)    0           conv2d_274[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_257 (Concatenate)   (None, 32, 32, 24)   0           conv2d_273[0][0]                 \n",
            "                                                                 dropout_269[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_274 (BatchN (None, 32, 32, 24)   96          concatenate_257[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_274 (Activation)     (None, 32, 32, 24)   0           batch_normalization_274[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_275 (Conv2D)             (None, 32, 32, 8)    1728        activation_274[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_270 (Dropout)           (None, 32, 32, 8)    0           conv2d_275[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_258 (Concatenate)   (None, 32, 32, 32)   0           concatenate_257[0][0]            \n",
            "                                                                 dropout_270[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_275 (BatchN (None, 32, 32, 32)   128         concatenate_258[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_275 (Activation)     (None, 32, 32, 32)   0           batch_normalization_275[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_276 (Conv2D)             (None, 32, 32, 8)    2304        activation_275[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_271 (Dropout)           (None, 32, 32, 8)    0           conv2d_276[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_259 (Concatenate)   (None, 32, 32, 40)   0           concatenate_258[0][0]            \n",
            "                                                                 dropout_271[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_276 (BatchN (None, 32, 32, 40)   160         concatenate_259[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_276 (Activation)     (None, 32, 32, 40)   0           batch_normalization_276[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_277 (Conv2D)             (None, 32, 32, 8)    2880        activation_276[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_272 (Dropout)           (None, 32, 32, 8)    0           conv2d_277[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_260 (Concatenate)   (None, 32, 32, 48)   0           concatenate_259[0][0]            \n",
            "                                                                 dropout_272[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_277 (BatchN (None, 32, 32, 48)   192         concatenate_260[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_277 (Activation)     (None, 32, 32, 48)   0           batch_normalization_277[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_278 (Conv2D)             (None, 32, 32, 8)    3456        activation_277[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_273 (Dropout)           (None, 32, 32, 8)    0           conv2d_278[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_261 (Concatenate)   (None, 32, 32, 56)   0           concatenate_260[0][0]            \n",
            "                                                                 dropout_273[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_278 (BatchN (None, 32, 32, 56)   224         concatenate_261[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_278 (Activation)     (None, 32, 32, 56)   0           batch_normalization_278[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_279 (Conv2D)             (None, 32, 32, 8)    4032        activation_278[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_274 (Dropout)           (None, 32, 32, 8)    0           conv2d_279[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_262 (Concatenate)   (None, 32, 32, 64)   0           concatenate_261[0][0]            \n",
            "                                                                 dropout_274[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_279 (BatchN (None, 32, 32, 64)   256         concatenate_262[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_279 (Activation)     (None, 32, 32, 64)   0           batch_normalization_279[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_280 (Conv2D)             (None, 32, 32, 8)    4608        activation_279[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_275 (Dropout)           (None, 32, 32, 8)    0           conv2d_280[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_263 (Concatenate)   (None, 32, 32, 72)   0           concatenate_262[0][0]            \n",
            "                                                                 dropout_275[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_280 (BatchN (None, 32, 32, 72)   288         concatenate_263[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_280 (Activation)     (None, 32, 32, 72)   0           batch_normalization_280[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_281 (Conv2D)             (None, 32, 32, 8)    5184        activation_280[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_276 (Dropout)           (None, 32, 32, 8)    0           conv2d_281[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_264 (Concatenate)   (None, 32, 32, 80)   0           concatenate_263[0][0]            \n",
            "                                                                 dropout_276[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_281 (BatchN (None, 32, 32, 80)   320         concatenate_264[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_281 (Activation)     (None, 32, 32, 80)   0           batch_normalization_281[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_282 (Conv2D)             (None, 32, 32, 8)    5760        activation_281[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_277 (Dropout)           (None, 32, 32, 8)    0           conv2d_282[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_265 (Concatenate)   (None, 32, 32, 88)   0           concatenate_264[0][0]            \n",
            "                                                                 dropout_277[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_282 (BatchN (None, 32, 32, 88)   352         concatenate_265[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_282 (Activation)     (None, 32, 32, 88)   0           batch_normalization_282[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_283 (Conv2D)             (None, 32, 32, 8)    6336        activation_282[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_278 (Dropout)           (None, 32, 32, 8)    0           conv2d_283[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_266 (Concatenate)   (None, 32, 32, 96)   0           concatenate_265[0][0]            \n",
            "                                                                 dropout_278[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_283 (BatchN (None, 32, 32, 96)   384         concatenate_266[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_283 (Activation)     (None, 32, 32, 96)   0           batch_normalization_283[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_284 (Conv2D)             (None, 32, 32, 8)    6912        activation_283[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_279 (Dropout)           (None, 32, 32, 8)    0           conv2d_284[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_267 (Concatenate)   (None, 32, 32, 104)  0           concatenate_266[0][0]            \n",
            "                                                                 dropout_279[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_284 (BatchN (None, 32, 32, 104)  416         concatenate_267[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_284 (Activation)     (None, 32, 32, 104)  0           batch_normalization_284[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_285 (Conv2D)             (None, 32, 32, 8)    7488        activation_284[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_280 (Dropout)           (None, 32, 32, 8)    0           conv2d_285[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_268 (Concatenate)   (None, 32, 32, 112)  0           concatenate_267[0][0]            \n",
            "                                                                 dropout_280[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_285 (BatchN (None, 32, 32, 112)  448         concatenate_268[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_285 (Activation)     (None, 32, 32, 112)  0           batch_normalization_285[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_286 (Conv2D)             (None, 32, 32, 8)    8064        activation_285[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_281 (Dropout)           (None, 32, 32, 8)    0           conv2d_286[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_269 (Concatenate)   (None, 32, 32, 120)  0           concatenate_268[0][0]            \n",
            "                                                                 dropout_281[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_286 (BatchN (None, 32, 32, 120)  480         concatenate_269[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_286 (Activation)     (None, 32, 32, 120)  0           batch_normalization_286[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_287 (Conv2D)             (None, 32, 32, 8)    8640        activation_286[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_282 (Dropout)           (None, 32, 32, 8)    0           conv2d_287[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_270 (Concatenate)   (None, 32, 32, 128)  0           concatenate_269[0][0]            \n",
            "                                                                 dropout_282[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_287 (BatchN (None, 32, 32, 128)  512         concatenate_270[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_287 (Activation)     (None, 32, 32, 128)  0           batch_normalization_287[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_288 (Conv2D)             (None, 32, 32, 8)    9216        activation_287[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_283 (Dropout)           (None, 32, 32, 8)    0           conv2d_288[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_271 (Concatenate)   (None, 32, 32, 136)  0           concatenate_270[0][0]            \n",
            "                                                                 dropout_283[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_288 (BatchN (None, 32, 32, 136)  544         concatenate_271[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_288 (Activation)     (None, 32, 32, 136)  0           batch_normalization_288[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_289 (Conv2D)             (None, 32, 32, 8)    9792        activation_288[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_284 (Dropout)           (None, 32, 32, 8)    0           conv2d_289[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_272 (Concatenate)   (None, 32, 32, 144)  0           concatenate_271[0][0]            \n",
            "                                                                 dropout_284[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_289 (BatchN (None, 32, 32, 144)  576         concatenate_272[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_289 (Activation)     (None, 32, 32, 144)  0           batch_normalization_289[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_290 (Conv2D)             (None, 32, 32, 8)    1152        activation_289[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_285 (Dropout)           (None, 32, 32, 8)    0           conv2d_290[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_17 (AveragePo (None, 16, 16, 8)    0           dropout_285[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_290 (BatchN (None, 16, 16, 8)    32          average_pooling2d_17[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_290 (Activation)     (None, 16, 16, 8)    0           batch_normalization_290[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_291 (Conv2D)             (None, 16, 16, 8)    576         activation_290[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_286 (Dropout)           (None, 16, 16, 8)    0           conv2d_291[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_273 (Concatenate)   (None, 16, 16, 16)   0           average_pooling2d_17[0][0]       \n",
            "                                                                 dropout_286[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_291 (BatchN (None, 16, 16, 16)   64          concatenate_273[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_291 (Activation)     (None, 16, 16, 16)   0           batch_normalization_291[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_292 (Conv2D)             (None, 16, 16, 8)    1152        activation_291[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_287 (Dropout)           (None, 16, 16, 8)    0           conv2d_292[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_274 (Concatenate)   (None, 16, 16, 24)   0           concatenate_273[0][0]            \n",
            "                                                                 dropout_287[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_292 (BatchN (None, 16, 16, 24)   96          concatenate_274[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_292 (Activation)     (None, 16, 16, 24)   0           batch_normalization_292[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_293 (Conv2D)             (None, 16, 16, 8)    1728        activation_292[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_288 (Dropout)           (None, 16, 16, 8)    0           conv2d_293[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_275 (Concatenate)   (None, 16, 16, 32)   0           concatenate_274[0][0]            \n",
            "                                                                 dropout_288[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_293 (BatchN (None, 16, 16, 32)   128         concatenate_275[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_293 (Activation)     (None, 16, 16, 32)   0           batch_normalization_293[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_294 (Conv2D)             (None, 16, 16, 8)    2304        activation_293[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_289 (Dropout)           (None, 16, 16, 8)    0           conv2d_294[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_276 (Concatenate)   (None, 16, 16, 40)   0           concatenate_275[0][0]            \n",
            "                                                                 dropout_289[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_294 (BatchN (None, 16, 16, 40)   160         concatenate_276[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_294 (Activation)     (None, 16, 16, 40)   0           batch_normalization_294[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_295 (Conv2D)             (None, 16, 16, 8)    2880        activation_294[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_290 (Dropout)           (None, 16, 16, 8)    0           conv2d_295[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_277 (Concatenate)   (None, 16, 16, 48)   0           concatenate_276[0][0]            \n",
            "                                                                 dropout_290[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_295 (BatchN (None, 16, 16, 48)   192         concatenate_277[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_295 (Activation)     (None, 16, 16, 48)   0           batch_normalization_295[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_296 (Conv2D)             (None, 16, 16, 8)    3456        activation_295[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_291 (Dropout)           (None, 16, 16, 8)    0           conv2d_296[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_278 (Concatenate)   (None, 16, 16, 56)   0           concatenate_277[0][0]            \n",
            "                                                                 dropout_291[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_296 (BatchN (None, 16, 16, 56)   224         concatenate_278[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_296 (Activation)     (None, 16, 16, 56)   0           batch_normalization_296[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_297 (Conv2D)             (None, 16, 16, 8)    4032        activation_296[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_292 (Dropout)           (None, 16, 16, 8)    0           conv2d_297[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_279 (Concatenate)   (None, 16, 16, 64)   0           concatenate_278[0][0]            \n",
            "                                                                 dropout_292[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_297 (BatchN (None, 16, 16, 64)   256         concatenate_279[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_297 (Activation)     (None, 16, 16, 64)   0           batch_normalization_297[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_298 (Conv2D)             (None, 16, 16, 8)    4608        activation_297[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_293 (Dropout)           (None, 16, 16, 8)    0           conv2d_298[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_280 (Concatenate)   (None, 16, 16, 72)   0           concatenate_279[0][0]            \n",
            "                                                                 dropout_293[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_298 (BatchN (None, 16, 16, 72)   288         concatenate_280[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_298 (Activation)     (None, 16, 16, 72)   0           batch_normalization_298[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_299 (Conv2D)             (None, 16, 16, 8)    5184        activation_298[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_294 (Dropout)           (None, 16, 16, 8)    0           conv2d_299[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_281 (Concatenate)   (None, 16, 16, 80)   0           concatenate_280[0][0]            \n",
            "                                                                 dropout_294[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_299 (BatchN (None, 16, 16, 80)   320         concatenate_281[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_299 (Activation)     (None, 16, 16, 80)   0           batch_normalization_299[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_300 (Conv2D)             (None, 16, 16, 8)    5760        activation_299[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_295 (Dropout)           (None, 16, 16, 8)    0           conv2d_300[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_282 (Concatenate)   (None, 16, 16, 88)   0           concatenate_281[0][0]            \n",
            "                                                                 dropout_295[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_300 (BatchN (None, 16, 16, 88)   352         concatenate_282[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_300 (Activation)     (None, 16, 16, 88)   0           batch_normalization_300[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_301 (Conv2D)             (None, 16, 16, 8)    6336        activation_300[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_296 (Dropout)           (None, 16, 16, 8)    0           conv2d_301[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_283 (Concatenate)   (None, 16, 16, 96)   0           concatenate_282[0][0]            \n",
            "                                                                 dropout_296[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_301 (BatchN (None, 16, 16, 96)   384         concatenate_283[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_301 (Activation)     (None, 16, 16, 96)   0           batch_normalization_301[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_302 (Conv2D)             (None, 16, 16, 8)    6912        activation_301[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_297 (Dropout)           (None, 16, 16, 8)    0           conv2d_302[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_284 (Concatenate)   (None, 16, 16, 104)  0           concatenate_283[0][0]            \n",
            "                                                                 dropout_297[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_302 (BatchN (None, 16, 16, 104)  416         concatenate_284[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_302 (Activation)     (None, 16, 16, 104)  0           batch_normalization_302[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_303 (Conv2D)             (None, 16, 16, 8)    7488        activation_302[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_298 (Dropout)           (None, 16, 16, 8)    0           conv2d_303[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_285 (Concatenate)   (None, 16, 16, 112)  0           concatenate_284[0][0]            \n",
            "                                                                 dropout_298[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_303 (BatchN (None, 16, 16, 112)  448         concatenate_285[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_303 (Activation)     (None, 16, 16, 112)  0           batch_normalization_303[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_304 (Conv2D)             (None, 16, 16, 8)    8064        activation_303[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_299 (Dropout)           (None, 16, 16, 8)    0           conv2d_304[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_286 (Concatenate)   (None, 16, 16, 120)  0           concatenate_285[0][0]            \n",
            "                                                                 dropout_299[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_304 (BatchN (None, 16, 16, 120)  480         concatenate_286[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_304 (Activation)     (None, 16, 16, 120)  0           batch_normalization_304[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_305 (Conv2D)             (None, 16, 16, 8)    8640        activation_304[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_300 (Dropout)           (None, 16, 16, 8)    0           conv2d_305[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_287 (Concatenate)   (None, 16, 16, 128)  0           concatenate_286[0][0]            \n",
            "                                                                 dropout_300[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_305 (BatchN (None, 16, 16, 128)  512         concatenate_287[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_305 (Activation)     (None, 16, 16, 128)  0           batch_normalization_305[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_306 (Conv2D)             (None, 16, 16, 8)    9216        activation_305[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_301 (Dropout)           (None, 16, 16, 8)    0           conv2d_306[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_288 (Concatenate)   (None, 16, 16, 136)  0           concatenate_287[0][0]            \n",
            "                                                                 dropout_301[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_306 (BatchN (None, 16, 16, 136)  544         concatenate_288[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_306 (Activation)     (None, 16, 16, 136)  0           batch_normalization_306[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_307 (Conv2D)             (None, 16, 16, 8)    1088        activation_306[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_302 (Dropout)           (None, 16, 16, 8)    0           conv2d_307[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_18 (AveragePo (None, 8, 8, 8)      0           dropout_302[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_307 (BatchN (None, 8, 8, 8)      32          average_pooling2d_18[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_307 (Activation)     (None, 8, 8, 8)      0           batch_normalization_307[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_308 (Conv2D)             (None, 8, 8, 8)      576         activation_307[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_303 (Dropout)           (None, 8, 8, 8)      0           conv2d_308[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_289 (Concatenate)   (None, 8, 8, 16)     0           average_pooling2d_18[0][0]       \n",
            "                                                                 dropout_303[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_308 (BatchN (None, 8, 8, 16)     64          concatenate_289[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_308 (Activation)     (None, 8, 8, 16)     0           batch_normalization_308[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_309 (Conv2D)             (None, 8, 8, 8)      1152        activation_308[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_304 (Dropout)           (None, 8, 8, 8)      0           conv2d_309[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_290 (Concatenate)   (None, 8, 8, 24)     0           concatenate_289[0][0]            \n",
            "                                                                 dropout_304[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_309 (BatchN (None, 8, 8, 24)     96          concatenate_290[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_309 (Activation)     (None, 8, 8, 24)     0           batch_normalization_309[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_310 (Conv2D)             (None, 8, 8, 8)      1728        activation_309[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_305 (Dropout)           (None, 8, 8, 8)      0           conv2d_310[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_291 (Concatenate)   (None, 8, 8, 32)     0           concatenate_290[0][0]            \n",
            "                                                                 dropout_305[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_310 (BatchN (None, 8, 8, 32)     128         concatenate_291[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_310 (Activation)     (None, 8, 8, 32)     0           batch_normalization_310[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_311 (Conv2D)             (None, 8, 8, 8)      2304        activation_310[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_306 (Dropout)           (None, 8, 8, 8)      0           conv2d_311[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_292 (Concatenate)   (None, 8, 8, 40)     0           concatenate_291[0][0]            \n",
            "                                                                 dropout_306[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_311 (BatchN (None, 8, 8, 40)     160         concatenate_292[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_311 (Activation)     (None, 8, 8, 40)     0           batch_normalization_311[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_312 (Conv2D)             (None, 8, 8, 8)      2880        activation_311[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_307 (Dropout)           (None, 8, 8, 8)      0           conv2d_312[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_293 (Concatenate)   (None, 8, 8, 48)     0           concatenate_292[0][0]            \n",
            "                                                                 dropout_307[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_312 (BatchN (None, 8, 8, 48)     192         concatenate_293[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_312 (Activation)     (None, 8, 8, 48)     0           batch_normalization_312[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_313 (Conv2D)             (None, 8, 8, 8)      3456        activation_312[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_308 (Dropout)           (None, 8, 8, 8)      0           conv2d_313[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_294 (Concatenate)   (None, 8, 8, 56)     0           concatenate_293[0][0]            \n",
            "                                                                 dropout_308[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_313 (BatchN (None, 8, 8, 56)     224         concatenate_294[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_313 (Activation)     (None, 8, 8, 56)     0           batch_normalization_313[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_314 (Conv2D)             (None, 8, 8, 8)      4032        activation_313[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_309 (Dropout)           (None, 8, 8, 8)      0           conv2d_314[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_295 (Concatenate)   (None, 8, 8, 64)     0           concatenate_294[0][0]            \n",
            "                                                                 dropout_309[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_314 (BatchN (None, 8, 8, 64)     256         concatenate_295[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_314 (Activation)     (None, 8, 8, 64)     0           batch_normalization_314[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_315 (Conv2D)             (None, 8, 8, 8)      4608        activation_314[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_310 (Dropout)           (None, 8, 8, 8)      0           conv2d_315[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_296 (Concatenate)   (None, 8, 8, 72)     0           concatenate_295[0][0]            \n",
            "                                                                 dropout_310[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_315 (BatchN (None, 8, 8, 72)     288         concatenate_296[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_315 (Activation)     (None, 8, 8, 72)     0           batch_normalization_315[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_316 (Conv2D)             (None, 8, 8, 8)      5184        activation_315[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_311 (Dropout)           (None, 8, 8, 8)      0           conv2d_316[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_297 (Concatenate)   (None, 8, 8, 80)     0           concatenate_296[0][0]            \n",
            "                                                                 dropout_311[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_316 (BatchN (None, 8, 8, 80)     320         concatenate_297[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_316 (Activation)     (None, 8, 8, 80)     0           batch_normalization_316[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_317 (Conv2D)             (None, 8, 8, 8)      5760        activation_316[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_312 (Dropout)           (None, 8, 8, 8)      0           conv2d_317[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_298 (Concatenate)   (None, 8, 8, 88)     0           concatenate_297[0][0]            \n",
            "                                                                 dropout_312[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_317 (BatchN (None, 8, 8, 88)     352         concatenate_298[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_317 (Activation)     (None, 8, 8, 88)     0           batch_normalization_317[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_318 (Conv2D)             (None, 8, 8, 8)      6336        activation_317[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_313 (Dropout)           (None, 8, 8, 8)      0           conv2d_318[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_299 (Concatenate)   (None, 8, 8, 96)     0           concatenate_298[0][0]            \n",
            "                                                                 dropout_313[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_318 (BatchN (None, 8, 8, 96)     384         concatenate_299[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_318 (Activation)     (None, 8, 8, 96)     0           batch_normalization_318[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_319 (Conv2D)             (None, 8, 8, 8)      6912        activation_318[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_314 (Dropout)           (None, 8, 8, 8)      0           conv2d_319[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_300 (Concatenate)   (None, 8, 8, 104)    0           concatenate_299[0][0]            \n",
            "                                                                 dropout_314[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_319 (BatchN (None, 8, 8, 104)    416         concatenate_300[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_319 (Activation)     (None, 8, 8, 104)    0           batch_normalization_319[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_320 (Conv2D)             (None, 8, 8, 8)      7488        activation_319[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_315 (Dropout)           (None, 8, 8, 8)      0           conv2d_320[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_301 (Concatenate)   (None, 8, 8, 112)    0           concatenate_300[0][0]            \n",
            "                                                                 dropout_315[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_320 (BatchN (None, 8, 8, 112)    448         concatenate_301[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_320 (Activation)     (None, 8, 8, 112)    0           batch_normalization_320[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_321 (Conv2D)             (None, 8, 8, 8)      8064        activation_320[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_316 (Dropout)           (None, 8, 8, 8)      0           conv2d_321[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_302 (Concatenate)   (None, 8, 8, 120)    0           concatenate_301[0][0]            \n",
            "                                                                 dropout_316[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_321 (BatchN (None, 8, 8, 120)    480         concatenate_302[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_321 (Activation)     (None, 8, 8, 120)    0           batch_normalization_321[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_322 (Conv2D)             (None, 8, 8, 8)      8640        activation_321[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_317 (Dropout)           (None, 8, 8, 8)      0           conv2d_322[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_303 (Concatenate)   (None, 8, 8, 128)    0           concatenate_302[0][0]            \n",
            "                                                                 dropout_317[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_322 (BatchN (None, 8, 8, 128)    512         concatenate_303[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_322 (Activation)     (None, 8, 8, 128)    0           batch_normalization_322[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_323 (Conv2D)             (None, 8, 8, 8)      9216        activation_322[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_318 (Dropout)           (None, 8, 8, 8)      0           conv2d_323[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_304 (Concatenate)   (None, 8, 8, 136)    0           concatenate_303[0][0]            \n",
            "                                                                 dropout_318[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_323 (BatchN (None, 8, 8, 136)    544         concatenate_304[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_323 (Activation)     (None, 8, 8, 136)    0           batch_normalization_323[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_324 (Conv2D)             (None, 8, 8, 8)      1088        activation_323[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_319 (Dropout)           (None, 8, 8, 8)      0           conv2d_324[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_19 (AveragePo (None, 4, 4, 8)      0           dropout_319[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_324 (BatchN (None, 4, 4, 8)      32          average_pooling2d_19[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_324 (Activation)     (None, 4, 4, 8)      0           batch_normalization_324[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_325 (Conv2D)             (None, 4, 4, 8)      576         activation_324[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_320 (Dropout)           (None, 4, 4, 8)      0           conv2d_325[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_305 (Concatenate)   (None, 4, 4, 16)     0           average_pooling2d_19[0][0]       \n",
            "                                                                 dropout_320[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_325 (BatchN (None, 4, 4, 16)     64          concatenate_305[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_325 (Activation)     (None, 4, 4, 16)     0           batch_normalization_325[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_326 (Conv2D)             (None, 4, 4, 8)      1152        activation_325[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_321 (Dropout)           (None, 4, 4, 8)      0           conv2d_326[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_306 (Concatenate)   (None, 4, 4, 24)     0           concatenate_305[0][0]            \n",
            "                                                                 dropout_321[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_326 (BatchN (None, 4, 4, 24)     96          concatenate_306[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_326 (Activation)     (None, 4, 4, 24)     0           batch_normalization_326[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_327 (Conv2D)             (None, 4, 4, 8)      1728        activation_326[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_322 (Dropout)           (None, 4, 4, 8)      0           conv2d_327[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_307 (Concatenate)   (None, 4, 4, 32)     0           concatenate_306[0][0]            \n",
            "                                                                 dropout_322[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_327 (BatchN (None, 4, 4, 32)     128         concatenate_307[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_327 (Activation)     (None, 4, 4, 32)     0           batch_normalization_327[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_328 (Conv2D)             (None, 4, 4, 8)      2304        activation_327[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_323 (Dropout)           (None, 4, 4, 8)      0           conv2d_328[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_308 (Concatenate)   (None, 4, 4, 40)     0           concatenate_307[0][0]            \n",
            "                                                                 dropout_323[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_328 (BatchN (None, 4, 4, 40)     160         concatenate_308[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_328 (Activation)     (None, 4, 4, 40)     0           batch_normalization_328[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_329 (Conv2D)             (None, 4, 4, 8)      2880        activation_328[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_324 (Dropout)           (None, 4, 4, 8)      0           conv2d_329[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_309 (Concatenate)   (None, 4, 4, 48)     0           concatenate_308[0][0]            \n",
            "                                                                 dropout_324[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_329 (BatchN (None, 4, 4, 48)     192         concatenate_309[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_329 (Activation)     (None, 4, 4, 48)     0           batch_normalization_329[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_330 (Conv2D)             (None, 4, 4, 8)      3456        activation_329[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_325 (Dropout)           (None, 4, 4, 8)      0           conv2d_330[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_310 (Concatenate)   (None, 4, 4, 56)     0           concatenate_309[0][0]            \n",
            "                                                                 dropout_325[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_330 (BatchN (None, 4, 4, 56)     224         concatenate_310[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_330 (Activation)     (None, 4, 4, 56)     0           batch_normalization_330[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_331 (Conv2D)             (None, 4, 4, 8)      4032        activation_330[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_326 (Dropout)           (None, 4, 4, 8)      0           conv2d_331[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_311 (Concatenate)   (None, 4, 4, 64)     0           concatenate_310[0][0]            \n",
            "                                                                 dropout_326[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_331 (BatchN (None, 4, 4, 64)     256         concatenate_311[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_331 (Activation)     (None, 4, 4, 64)     0           batch_normalization_331[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_332 (Conv2D)             (None, 4, 4, 8)      4608        activation_331[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_327 (Dropout)           (None, 4, 4, 8)      0           conv2d_332[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_312 (Concatenate)   (None, 4, 4, 72)     0           concatenate_311[0][0]            \n",
            "                                                                 dropout_327[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_332 (BatchN (None, 4, 4, 72)     288         concatenate_312[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_332 (Activation)     (None, 4, 4, 72)     0           batch_normalization_332[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_333 (Conv2D)             (None, 4, 4, 8)      5184        activation_332[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_328 (Dropout)           (None, 4, 4, 8)      0           conv2d_333[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_313 (Concatenate)   (None, 4, 4, 80)     0           concatenate_312[0][0]            \n",
            "                                                                 dropout_328[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_333 (BatchN (None, 4, 4, 80)     320         concatenate_313[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_333 (Activation)     (None, 4, 4, 80)     0           batch_normalization_333[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_334 (Conv2D)             (None, 4, 4, 8)      5760        activation_333[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_329 (Dropout)           (None, 4, 4, 8)      0           conv2d_334[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_314 (Concatenate)   (None, 4, 4, 88)     0           concatenate_313[0][0]            \n",
            "                                                                 dropout_329[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_334 (BatchN (None, 4, 4, 88)     352         concatenate_314[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_334 (Activation)     (None, 4, 4, 88)     0           batch_normalization_334[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_335 (Conv2D)             (None, 4, 4, 8)      6336        activation_334[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_330 (Dropout)           (None, 4, 4, 8)      0           conv2d_335[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_315 (Concatenate)   (None, 4, 4, 96)     0           concatenate_314[0][0]            \n",
            "                                                                 dropout_330[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_335 (BatchN (None, 4, 4, 96)     384         concatenate_315[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_335 (Activation)     (None, 4, 4, 96)     0           batch_normalization_335[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_336 (Conv2D)             (None, 4, 4, 8)      6912        activation_335[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_331 (Dropout)           (None, 4, 4, 8)      0           conv2d_336[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_316 (Concatenate)   (None, 4, 4, 104)    0           concatenate_315[0][0]            \n",
            "                                                                 dropout_331[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_336 (BatchN (None, 4, 4, 104)    416         concatenate_316[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_336 (Activation)     (None, 4, 4, 104)    0           batch_normalization_336[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_337 (Conv2D)             (None, 4, 4, 8)      7488        activation_336[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_332 (Dropout)           (None, 4, 4, 8)      0           conv2d_337[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_317 (Concatenate)   (None, 4, 4, 112)    0           concatenate_316[0][0]            \n",
            "                                                                 dropout_332[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_337 (BatchN (None, 4, 4, 112)    448         concatenate_317[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_337 (Activation)     (None, 4, 4, 112)    0           batch_normalization_337[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_338 (Conv2D)             (None, 4, 4, 8)      8064        activation_337[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_333 (Dropout)           (None, 4, 4, 8)      0           conv2d_338[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_318 (Concatenate)   (None, 4, 4, 120)    0           concatenate_317[0][0]            \n",
            "                                                                 dropout_333[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_338 (BatchN (None, 4, 4, 120)    480         concatenate_318[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_338 (Activation)     (None, 4, 4, 120)    0           batch_normalization_338[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_339 (Conv2D)             (None, 4, 4, 8)      8640        activation_338[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_334 (Dropout)           (None, 4, 4, 8)      0           conv2d_339[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_319 (Concatenate)   (None, 4, 4, 128)    0           concatenate_318[0][0]            \n",
            "                                                                 dropout_334[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_339 (BatchN (None, 4, 4, 128)    512         concatenate_319[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_339 (Activation)     (None, 4, 4, 128)    0           batch_normalization_339[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_340 (Conv2D)             (None, 4, 4, 8)      9216        activation_339[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_335 (Dropout)           (None, 4, 4, 8)      0           conv2d_340[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_320 (Concatenate)   (None, 4, 4, 136)    0           concatenate_319[0][0]            \n",
            "                                                                 dropout_335[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_340 (BatchN (None, 4, 4, 136)    544         concatenate_320[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_340 (Activation)     (None, 4, 4, 136)    0           batch_normalization_340[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_20 (AveragePo (None, 2, 2, 136)    0           activation_340[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_5 (Flatten)             (None, 544)          0           average_pooling2d_20[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 10)           5450        flatten_5[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 351,898\n",
            "Trainable params: 341,834\n",
            "Non-trainable params: 10,064\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b4XOsW3ahSkL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# determine Loss function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "crhGk7kEhXAz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1368
        },
        "outputId": "0553499c-f0ec-4e5e-bf91-52fa342519e3"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model.fit(new_images, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(new_test, y_test),callbacks=cb)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "34200/50000 [===================>..........] - ETA: 1:19 - loss: 1.7327 - acc: 0.3490"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 255s 5ms/step - loss: 1.6479 - acc: 0.3841 - val_loss: 1.5614 - val_acc: 0.4559\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploading file 4B_008_0.4558999978005886.h5 to folder Colab Notebooks: 100%|██████████| 100/100 [00:00<00:00, 110.95it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 233s 5ms/step - loss: 1.3056 - acc: 0.5242 - val_loss: 1.2291 - val_acc: 0.5664\n",
            "Removing old cloud file 4B_008_0.4558999978005886.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploading file 4B_008_0.5664000003039837.h5 to folder Colab Notebooks: 100%|██████████| 100/100 [00:00<00:00, 148.75it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 233s 5ms/step - loss: 1.1323 - acc: 0.5906 - val_loss: 1.4028 - val_acc: 0.5411\n",
            "No improvement.\n",
            "Epoch 4/20\n",
            "  800/50000 [..............................] - ETA: 3:36 - loss: 1.0584 - acc: 0.6338"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 232s 5ms/step - loss: 1.0235 - acc: 0.6343 - val_loss: 1.1642 - val_acc: 0.6030\n",
            "Removing old cloud file 4B_008_0.5664000003039837.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploading file 4B_008_0.6030000016093254.h5 to folder Colab Notebooks: 100%|██████████| 100/100 [00:00<00:00, 127.94it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 233s 5ms/step - loss: 0.9498 - acc: 0.6610 - val_loss: 1.0167 - val_acc: 0.6601\n",
            "Removing old cloud file 4B_008_0.6030000016093254.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploading file 4B_008_0.6601000061631203.h5 to folder Colab Notebooks: 100%|██████████| 100/100 [00:00<00:00, 124.90it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 233s 5ms/step - loss: 0.8865 - acc: 0.6877 - val_loss: 1.2175 - val_acc: 0.5932\n",
            "No improvement.\n",
            "Epoch 7/20\n",
            "  800/50000 [..............................] - ETA: 3:37 - loss: 0.8683 - acc: 0.6675"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 232s 5ms/step - loss: 0.8368 - acc: 0.7052 - val_loss: 0.9775 - val_acc: 0.6752\n",
            "Removing old cloud file 4B_008_0.6601000061631203.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploading file 4B_008_0.6752000039815903.h5 to folder Colab Notebooks: 100%|██████████| 100/100 [00:00<00:00, 122.27it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 232s 5ms/step - loss: 0.7973 - acc: 0.7205 - val_loss: 0.9455 - val_acc: 0.6844\n",
            "Removing old cloud file 4B_008_0.6752000039815903.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploading file 4B_008_0.6844000042974949.h5 to folder Colab Notebooks: 100%|██████████| 100/100 [00:00<00:00, 133.52it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 232s 5ms/step - loss: 0.7595 - acc: 0.7329 - val_loss: 0.9756 - val_acc: 0.6797\n",
            "No improvement.\n",
            "Epoch 10/20\n",
            "  800/50000 [..............................] - ETA: 3:35 - loss: 0.7414 - acc: 0.7288"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 231s 5ms/step - loss: 0.7329 - acc: 0.7428 - val_loss: 0.8292 - val_acc: 0.7200\n",
            "Removing old cloud file 4B_008_0.6844000042974949.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploading file 4B_008_0.7200000047683716.h5 to folder Colab Notebooks: 100%|██████████| 100/100 [00:00<00:00, 128.77it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 232s 5ms/step - loss: 0.7089 - acc: 0.7526 - val_loss: 0.8273 - val_acc: 0.7318\n",
            "Removing old cloud file 4B_008_0.7200000047683716.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploading file 4B_008_0.7318000015616417.h5 to folder Colab Notebooks: 100%|██████████| 100/100 [00:00<00:00, 108.10it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 232s 5ms/step - loss: 0.6806 - acc: 0.7630 - val_loss: 0.7857 - val_acc: 0.7455\n",
            "Removing old cloud file 4B_008_0.7318000015616417.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploading file 4B_008_0.7454999989271164.h5 to folder Colab Notebooks: 100%|██████████| 100/100 [00:00<00:00, 141.68it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 232s 5ms/step - loss: 0.6640 - acc: 0.7659 - val_loss: 0.8042 - val_acc: 0.7394\n",
            "No improvement.\n",
            "Epoch 14/20\n",
            "  600/50000 [..............................] - ETA: 3:36 - loss: 0.6663 - acc: 0.7600"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 232s 5ms/step - loss: 0.6396 - acc: 0.7742 - val_loss: 0.7262 - val_acc: 0.7675\n",
            "Removing old cloud file 4B_008_0.7454999989271164.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploading file 4B_008_0.7674999979138374.h5 to folder Colab Notebooks: 100%|██████████| 100/100 [00:00<00:00, 108.63it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 232s 5ms/step - loss: 0.6257 - acc: 0.7820 - val_loss: 0.8407 - val_acc: 0.7401\n",
            "No improvement.\n",
            "Epoch 16/20\n",
            "  600/50000 [..............................] - ETA: 3:35 - loss: 0.5991 - acc: 0.7867"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 232s 5ms/step - loss: 0.6029 - acc: 0.7893 - val_loss: 0.8521 - val_acc: 0.7394\n",
            "No improvement.\n",
            "Epoch 17/20\n",
            " 3300/50000 [>.............................] - ETA: 3:26 - loss: 0.5808 - acc: 0.7952"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 232s 5ms/step - loss: 0.5918 - acc: 0.7937 - val_loss: 0.8687 - val_acc: 0.7379\n",
            "No improvement.\n",
            "Epoch 18/20\n",
            " 4300/50000 [=>............................] - ETA: 3:20 - loss: 0.5614 - acc: 0.8019"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 232s 5ms/step - loss: 0.5797 - acc: 0.7972 - val_loss: 0.6581 - val_acc: 0.7909\n",
            "Removing old cloud file 4B_008_0.7674999979138374.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploading file 4B_008_0.7908999955654145.h5 to folder Colab Notebooks: 100%|██████████| 100/100 [00:00<00:00, 137.71it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 232s 5ms/step - loss: 0.5629 - acc: 0.8021 - val_loss: 0.7691 - val_acc: 0.7646\n",
            "No improvement.\n",
            "Epoch 20/20\n",
            "  600/50000 [..............................] - ETA: 3:40 - loss: 0.5497 - acc: 0.8167"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 232s 5ms/step - loss: 0.5529 - acc: 0.8077 - val_loss: 0.6630 - val_acc: 0.7893\n",
            "No improvement.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7ad63cda90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "metadata": {
        "id": "l_y5QoBdE4ls",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5e23f7d6-ab29-4213-cc3a-b695178b7de7"
      },
      "cell_type": "code",
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "model.save_weights(\"saved_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "O-t0iXljfSsk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "ae02b294-7163-4aa6-f10c-0e9d67d8e49d"
      },
      "cell_type": "code",
      "source": [
        "!ls -lrt\n",
        "!date"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 19856\r\n",
            "-rwxr-xr-x 1 root root 16117632 Jul 15  2017 ngrok\r\n",
            "-rw-r--r-- 1 root root     5214 May 27 10:16 tboard.py\r\n",
            "drwxr-xr-x 2 root root     4096 May 27 10:16 __pycache__\r\n",
            "drwxr-xr-x 2 root root     4096 May 27 10:16 log\r\n",
            "drwxr-xr-x 1 root root     4096 May 27 10:16 datalab\r\n",
            "-rw-r--r-- 1 root root     6935 May 27 10:30 utils.py\r\n",
            "-rw-r--r-- 1 root root  2154152 May 27 11:53 4B_008_0.7908999955654145.h5\r\n",
            "-rw-r--r-- 1 root root  2022968 May 27 12:01 saved_model.h5\n",
            "Sun May 27 12:07:59 UTC 2018\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ai-yZ2ED5AK1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#from google.colab import files\n",
        "\n",
        "#files.download('DNST_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vg-TFe5ggBbD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5ac75b60-4730-45e2-cb6c-b891ffa7ec0c"
      },
      "cell_type": "code",
      "source": [
        "print (x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bQyRgwvfhJb8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ce61769f-537f-482b-bdaf-7374035d3947"
      },
      "cell_type": "code",
      "source": [
        "num_filter = 16\n",
        "dropout_rate = 0.2\n",
        "l = 16\n",
        "inputs = Input(shape=(img_height, img_width, channel,))\n",
        "print(channel)\n",
        "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block = add_denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)\n",
        "#output = output_layer(First_Block)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Og56VCRh5j8V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1793
        },
        "outputId": "9a26f05d-63b9-4cfb-f7b5-139fce40f1c4"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#model = Model(inputs=[inputs], outputs=[output])\n",
        "model.load_weights('saved_model.h5',by_name=True)\n",
        "epochss =30\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochss,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test),callbacks=cb)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "34150/50000 [===================>..........] - ETA: 1:55 - loss: 1.6874 - acc: 0.3693"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 376s 8ms/step - loss: 1.5842 - acc: 0.4114 - val_loss: 1.7178 - val_acc: 0.4576\n",
            "No improvement.\n",
            "Epoch 2/30\n",
            "15250/50000 [========>.....................] - ETA: 3:49 - loss: 1.2658 - acc: 0.5386"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 352s 7ms/step - loss: 1.1912 - acc: 0.5694 - val_loss: 1.3218 - val_acc: 0.5601\n",
            "No improvement.\n",
            "Epoch 3/30\n",
            " 8500/50000 [====>.........................] - ETA: 4:34 - loss: 1.0693 - acc: 0.6121"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 351s 7ms/step - loss: 1.0312 - acc: 0.6293 - val_loss: 1.4254 - val_acc: 0.5505\n",
            "No improvement.\n",
            "Epoch 4/30\n",
            " 6100/50000 [==>...........................] - ETA: 4:49 - loss: 0.9784 - acc: 0.6487"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 351s 7ms/step - loss: 0.9387 - acc: 0.6669 - val_loss: 1.1552 - val_acc: 0.6316\n",
            "No improvement.\n",
            "Epoch 5/30\n",
            " 5250/50000 [==>...........................] - ETA: 4:54 - loss: 0.8585 - acc: 0.6872"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 351s 7ms/step - loss: 0.8643 - acc: 0.6922 - val_loss: 1.5196 - val_acc: 0.5821\n",
            "No improvement.\n",
            "Epoch 6/30\n",
            " 4950/50000 [=>............................] - ETA: 4:57 - loss: 0.7769 - acc: 0.7232"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 351s 7ms/step - loss: 0.8070 - acc: 0.7121 - val_loss: 1.2010 - val_acc: 0.6139\n",
            "No improvement.\n",
            "Epoch 7/30\n",
            " 4850/50000 [=>............................] - ETA: 4:58 - loss: 0.7578 - acc: 0.7272"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 351s 7ms/step - loss: 0.7592 - acc: 0.7293 - val_loss: 0.9623 - val_acc: 0.6995\n",
            "No improvement.\n",
            "Epoch 8/30\n",
            " 4800/50000 [=>............................] - ETA: 4:58 - loss: 0.7157 - acc: 0.7475"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 351s 7ms/step - loss: 0.7115 - acc: 0.7470 - val_loss: 1.0356 - val_acc: 0.6826\n",
            "No improvement.\n",
            "Epoch 9/30\n",
            " 4800/50000 [=>............................] - ETA: 4:59 - loss: 0.6776 - acc: 0.7631"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 350s 7ms/step - loss: 0.6762 - acc: 0.7620 - val_loss: 0.8907 - val_acc: 0.7226\n",
            "No improvement.\n",
            "Epoch 10/30\n",
            " 4800/50000 [=>............................] - ETA: 4:57 - loss: 0.6205 - acc: 0.7783"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 350s 7ms/step - loss: 0.6469 - acc: 0.7715 - val_loss: 0.7842 - val_acc: 0.7482\n",
            "No improvement.\n",
            "Epoch 11/30\n",
            " 4800/50000 [=>............................] - ETA: 4:58 - loss: 0.6150 - acc: 0.7790"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 349s 7ms/step - loss: 0.6202 - acc: 0.7821 - val_loss: 1.0701 - val_acc: 0.6855\n",
            "No improvement.\n",
            "Epoch 12/30\n",
            " 4800/50000 [=>............................] - ETA: 4:56 - loss: 0.5947 - acc: 0.7948"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 349s 7ms/step - loss: 0.5972 - acc: 0.7914 - val_loss: 0.7628 - val_acc: 0.7565\n",
            "No improvement.\n",
            "Epoch 13/30\n",
            " 4800/50000 [=>............................] - ETA: 4:57 - loss: 0.5663 - acc: 0.7996"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 350s 7ms/step - loss: 0.5770 - acc: 0.7966 - val_loss: 0.8723 - val_acc: 0.7383\n",
            "No improvement.\n",
            "Epoch 14/30\n",
            " 4800/50000 [=>............................] - ETA: 4:57 - loss: 0.5201 - acc: 0.8198"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 350s 7ms/step - loss: 0.5602 - acc: 0.8023 - val_loss: 0.8708 - val_acc: 0.7490\n",
            "No improvement.\n",
            "Epoch 15/30\n",
            " 4800/50000 [=>............................] - ETA: 4:57 - loss: 0.5272 - acc: 0.8198"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 349s 7ms/step - loss: 0.5395 - acc: 0.8109 - val_loss: 0.9485 - val_acc: 0.7289\n",
            "No improvement.\n",
            "Epoch 16/30\n",
            " 4800/50000 [=>............................] - ETA: 4:57 - loss: 0.5066 - acc: 0.8156"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 349s 7ms/step - loss: 0.5210 - acc: 0.8151 - val_loss: 0.7202 - val_acc: 0.7758\n",
            "No improvement.\n",
            "Epoch 17/30\n",
            " 4800/50000 [=>............................] - ETA: 4:55 - loss: 0.4924 - acc: 0.8233"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 348s 7ms/step - loss: 0.5103 - acc: 0.8213 - val_loss: 0.7332 - val_acc: 0.7750\n",
            "No improvement.\n",
            "Epoch 18/30\n",
            " 4800/50000 [=>............................] - ETA: 4:55 - loss: 0.4666 - acc: 0.8390"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 349s 7ms/step - loss: 0.4919 - acc: 0.8288 - val_loss: 0.8415 - val_acc: 0.7548\n",
            "No improvement.\n",
            "Epoch 19/30\n",
            " 4800/50000 [=>............................] - ETA: 4:56 - loss: 0.4738 - acc: 0.8269"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 349s 7ms/step - loss: 0.4845 - acc: 0.8292 - val_loss: 1.0103 - val_acc: 0.7332\n",
            "No improvement.\n",
            "Epoch 20/30\n",
            " 4800/50000 [=>............................] - ETA: 4:56 - loss: 0.4613 - acc: 0.8465"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 348s 7ms/step - loss: 0.4674 - acc: 0.8356 - val_loss: 0.5952 - val_acc: 0.8155\n",
            "Removing old cloud file 4B_008_0.7908999955654145.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploading file 4B_008_0.8154999950528145.h5 to folder Colab Notebooks: 100%|██████████| 100/100 [00:01<00:00, 96.86it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 21/30\n",
            "50000/50000 [==============================] - 349s 7ms/step - loss: 0.4594 - acc: 0.8391 - val_loss: 0.6783 - val_acc: 0.7972\n",
            "No improvement.\n",
            "Epoch 22/30\n",
            "  550/50000 [..............................] - ETA: 5:24 - loss: 0.4169 - acc: 0.8527"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 348s 7ms/step - loss: 0.4486 - acc: 0.8417 - val_loss: 0.7564 - val_acc: 0.7749\n",
            "No improvement.\n",
            "Epoch 23/30\n",
            " 3300/50000 [>.............................] - ETA: 5:05 - loss: 0.4284 - acc: 0.8470"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 348s 7ms/step - loss: 0.4387 - acc: 0.8476 - val_loss: 0.5939 - val_acc: 0.8131\n",
            "No improvement.\n",
            "Epoch 24/30\n",
            " 4250/50000 [=>............................] - ETA: 4:59 - loss: 0.4300 - acc: 0.8534"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 348s 7ms/step - loss: 0.4341 - acc: 0.8477 - val_loss: 0.6448 - val_acc: 0.8075\n",
            "No improvement.\n",
            "Epoch 25/30\n",
            " 4600/50000 [=>............................] - ETA: 4:56 - loss: 0.4194 - acc: 0.8533"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 348s 7ms/step - loss: 0.4214 - acc: 0.8512 - val_loss: 0.6661 - val_acc: 0.8052\n",
            "No improvement.\n",
            "Epoch 26/30\n",
            " 4700/50000 [=>............................] - ETA: 4:57 - loss: 0.4049 - acc: 0.8562"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 348s 7ms/step - loss: 0.4130 - acc: 0.8543 - val_loss: 0.6423 - val_acc: 0.8068\n",
            "No improvement.\n",
            "Epoch 27/30\n",
            " 4750/50000 [=>............................] - ETA: 4:52 - loss: 0.3848 - acc: 0.8653"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 346s 7ms/step - loss: 0.4036 - acc: 0.8588 - val_loss: 0.6397 - val_acc: 0.8162\n",
            "Removing old cloud file 4B_008_0.8154999950528145.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploading file 4B_008_0.8161999955773354.h5 to folder Colab Notebooks: 100%|██████████| 100/100 [00:01<00:00, 91.34it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 28/30\n",
            "50000/50000 [==============================] - 345s 7ms/step - loss: 0.3962 - acc: 0.8627 - val_loss: 0.5887 - val_acc: 0.8224\n",
            "Removing old cloud file 4B_008_0.8161999955773354.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploading file 4B_008_0.822399994134903.h5 to folder Colab Notebooks: 100%|██████████| 100/100 [00:00<00:00, 118.73it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 29/30\n",
            "50000/50000 [==============================] - 348s 7ms/step - loss: 0.3929 - acc: 0.8602 - val_loss: 0.6546 - val_acc: 0.8087\n",
            "No improvement.\n",
            "Epoch 30/30\n",
            "  550/50000 [..............................] - ETA: 5:20 - loss: 0.3459 - acc: 0.8855"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 347s 7ms/step - loss: 0.3874 - acc: 0.8628 - val_loss: 0.6415 - val_acc: 0.8153\n",
            "No improvement.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7acd650400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "metadata": {
        "id": "erTTykI0UEZR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1811
        },
        "outputId": "585d6d76-b793-4e99-f77b-c84e5c61445c"
      },
      "cell_type": "code",
      "source": [
        "model.load_weights('saved_model.h5',by_name=True)\n",
        "epochss =30\n",
        "'''\n",
        "model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochss,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test),callbacks=cb)\n",
        "'''\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size), epochs=epochss, \n",
        "                    verbose=1, validation_data=(x_test, y_test),\n",
        "                    steps_per_epoch=len(x_train)/batch_size, callbacks=cb)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1000/1000 [==============================] - 360s 360ms/step - loss: 0.6260 - acc: 0.7819 - val_loss: 0.7366 - val_acc: 0.7843\n",
            "No improvement.\n",
            "Epoch 2/30\n",
            "  24/1000 [..............................] - ETA: 5:28 - loss: 0.5138 - acc: 0.8225"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 359s 359ms/step - loss: 0.5957 - acc: 0.7902 - val_loss: 0.8158 - val_acc: 0.7667\n",
            "No improvement.\n",
            "Epoch 3/30\n",
            "  79/1000 [=>............................] - ETA: 5:12 - loss: 0.5637 - acc: 0.8028"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 361s 361ms/step - loss: 0.5902 - acc: 0.7923 - val_loss: 0.6170 - val_acc: 0.8139\n",
            "No improvement.\n",
            "Epoch 4/30\n",
            "  99/1000 [=>............................] - ETA: 5:06 - loss: 0.5559 - acc: 0.8069"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 360s 360ms/step - loss: 0.5758 - acc: 0.7982 - val_loss: 0.8708 - val_acc: 0.7609\n",
            "No improvement.\n",
            "Epoch 5/30\n",
            " 106/1000 [==>...........................] - ETA: 4:59 - loss: 0.5464 - acc: 0.8106"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 358s 358ms/step - loss: 0.5658 - acc: 0.8033 - val_loss: 0.6625 - val_acc: 0.8041\n",
            "No improvement.\n",
            "Epoch 6/30\n",
            " 108/1000 [==>...........................] - ETA: 4:59 - loss: 0.5822 - acc: 0.7943"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 359s 359ms/step - loss: 0.5615 - acc: 0.8042 - val_loss: 0.6332 - val_acc: 0.8096\n",
            "No improvement.\n",
            "Epoch 7/30\n",
            " 109/1000 [==>...........................] - ETA: 5:05 - loss: 0.5383 - acc: 0.8110"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 360s 360ms/step - loss: 0.5554 - acc: 0.8047 - val_loss: 0.7707 - val_acc: 0.7776\n",
            "No improvement.\n",
            "Epoch 8/30\n",
            " 109/1000 [==>...........................] - ETA: 5:02 - loss: 0.5502 - acc: 0.8094"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 359s 359ms/step - loss: 0.5482 - acc: 0.8087 - val_loss: 0.6142 - val_acc: 0.8133\n",
            "No improvement.\n",
            "Epoch 9/30\n",
            " 109/1000 [==>...........................] - ETA: 5:01 - loss: 0.5550 - acc: 0.8075"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 359s 359ms/step - loss: 0.5371 - acc: 0.8127 - val_loss: 0.5758 - val_acc: 0.8269\n",
            "Removing old cloud file 4B_008_0.822399994134903.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploading file 4B_008_0.8268999952077866.h5 to folder Colab Notebooks: 100%|██████████| 100/100 [00:00<00:00, 126.60it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/30\n",
            "1000/1000 [==============================] - 361s 361ms/step - loss: 0.5325 - acc: 0.8147 - val_loss: 0.6426 - val_acc: 0.8126\n",
            "No improvement.\n",
            "Epoch 11/30\n",
            "  19/1000 [..............................] - ETA: 5:30 - loss: 0.4927 - acc: 0.8368"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 358s 358ms/step - loss: 0.5362 - acc: 0.8114 - val_loss: 0.6259 - val_acc: 0.8159\n",
            "No improvement.\n",
            "Epoch 12/30\n",
            "  77/1000 [=>............................] - ETA: 5:14 - loss: 0.5158 - acc: 0.8106"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 359s 359ms/step - loss: 0.5289 - acc: 0.8136 - val_loss: 0.6635 - val_acc: 0.7980\n",
            "No improvement.\n",
            "Epoch 13/30\n",
            "  97/1000 [=>............................] - ETA: 5:05 - loss: 0.5385 - acc: 0.8074"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 357s 357ms/step - loss: 0.5236 - acc: 0.8177 - val_loss: 0.6835 - val_acc: 0.8010\n",
            "No improvement.\n",
            "Epoch 14/30\n",
            " 104/1000 [==>...........................] - ETA: 5:00 - loss: 0.5068 - acc: 0.8185"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 358s 358ms/step - loss: 0.5203 - acc: 0.8178 - val_loss: 0.6304 - val_acc: 0.8100\n",
            "No improvement.\n",
            "Epoch 15/30\n",
            " 107/1000 [==>...........................] - ETA: 5:00 - loss: 0.5113 - acc: 0.8202"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 359s 359ms/step - loss: 0.5127 - acc: 0.8224 - val_loss: 0.5877 - val_acc: 0.8278\n",
            "Removing old cloud file 4B_008_0.8268999952077866.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploading file 4B_008_0.827799996137619.h5 to folder Colab Notebooks: 100%|██████████| 100/100 [00:00<00:00, 121.74it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 16/30\n",
            "1000/1000 [==============================] - 359s 359ms/step - loss: 0.5164 - acc: 0.8193 - val_loss: 0.8080 - val_acc: 0.7735\n",
            "No improvement.\n",
            "Epoch 17/30\n",
            "  19/1000 [..............................] - ETA: 5:31 - loss: 0.5158 - acc: 0.8105"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 360s 360ms/step - loss: 0.5090 - acc: 0.8216 - val_loss: 0.6009 - val_acc: 0.8253\n",
            "No improvement.\n",
            "Epoch 18/30\n",
            "  77/1000 [=>............................] - ETA: 5:10 - loss: 0.5052 - acc: 0.8309"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 360s 360ms/step - loss: 0.5029 - acc: 0.8233 - val_loss: 0.6577 - val_acc: 0.8104\n",
            "No improvement.\n",
            "Epoch 19/30\n",
            "  97/1000 [=>............................] - ETA: 5:07 - loss: 0.5103 - acc: 0.8188"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 360s 360ms/step - loss: 0.4965 - acc: 0.8269 - val_loss: 0.6015 - val_acc: 0.8177\n",
            "No improvement.\n",
            "Epoch 20/30\n",
            " 104/1000 [==>...........................] - ETA: 5:02 - loss: 0.4751 - acc: 0.8327"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 360s 360ms/step - loss: 0.5006 - acc: 0.8263 - val_loss: 0.6222 - val_acc: 0.8221\n",
            "No improvement.\n",
            "Epoch 21/30\n",
            " 107/1000 [==>...........................] - ETA: 5:02 - loss: 0.4983 - acc: 0.8207"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 358s 358ms/step - loss: 0.4969 - acc: 0.8274 - val_loss: 0.5476 - val_acc: 0.8328\n",
            "Removing old cloud file 4B_008_0.827799996137619.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploading file 4B_008_0.8327999952435493.h5 to folder Colab Notebooks: 100%|██████████| 100/100 [00:00<00:00, 123.99it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 22/30\n",
            "1000/1000 [==============================] - 360s 360ms/step - loss: 0.4892 - acc: 0.8292 - val_loss: 0.6961 - val_acc: 0.8051\n",
            "No improvement.\n",
            "Epoch 23/30\n",
            "  19/1000 [..............................] - ETA: 5:30 - loss: 0.5538 - acc: 0.8021"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 360s 360ms/step - loss: 0.4824 - acc: 0.8315 - val_loss: 0.7665 - val_acc: 0.7859\n",
            "No improvement.\n",
            "Epoch 24/30\n",
            "  77/1000 [=>............................] - ETA: 5:11 - loss: 0.4500 - acc: 0.8436"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 360s 360ms/step - loss: 0.4763 - acc: 0.8325 - val_loss: 0.6602 - val_acc: 0.8124\n",
            "No improvement.\n",
            "Epoch 25/30\n",
            "  97/1000 [=>............................] - ETA: 5:07 - loss: 0.4775 - acc: 0.8318"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 360s 360ms/step - loss: 0.4793 - acc: 0.8323 - val_loss: 0.6192 - val_acc: 0.8237\n",
            "No improvement.\n",
            "Epoch 26/30\n",
            " 104/1000 [==>...........................] - ETA: 5:03 - loss: 0.4793 - acc: 0.8337"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 359s 359ms/step - loss: 0.4787 - acc: 0.8339 - val_loss: 0.5149 - val_acc: 0.8421\n",
            "Removing old cloud file 4B_008_0.8327999952435493.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploading file 4B_008_0.8420999947190285.h5 to folder Colab Notebooks: 100%|██████████| 100/100 [00:00<00:00, 104.22it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 27/30\n",
            "1000/1000 [==============================] - 359s 359ms/step - loss: 0.4770 - acc: 0.8323 - val_loss: 0.5829 - val_acc: 0.8332\n",
            "No improvement.\n",
            "Epoch 28/30\n",
            "  19/1000 [..............................] - ETA: 5:27 - loss: 0.4919 - acc: 0.8211"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 360s 360ms/step - loss: 0.4736 - acc: 0.8343 - val_loss: 0.5341 - val_acc: 0.8376\n",
            "No improvement.\n",
            "Epoch 29/30\n",
            "  77/1000 [=>............................] - ETA: 5:10 - loss: 0.4577 - acc: 0.8423"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 359s 359ms/step - loss: 0.4612 - acc: 0.8391 - val_loss: 0.8172 - val_acc: 0.7774\n",
            "No improvement.\n",
            "Epoch 30/30\n",
            "  97/1000 [=>............................] - ETA: 5:04 - loss: 0.4663 - acc: 0.8320"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 359s 359ms/step - loss: 0.4682 - acc: 0.8359 - val_loss: 0.5245 - val_acc: 0.8430\n",
            "Removing old cloud file 4B_008_0.8420999947190285.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploading file 4B_008_0.842999995648861.h5 to folder Colab Notebooks: 100%|██████████| 100/100 [00:00<00:00, 130.93it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7acb209b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "metadata": {
        "id": "aVnVxRaxkW_D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    }
  ]
}