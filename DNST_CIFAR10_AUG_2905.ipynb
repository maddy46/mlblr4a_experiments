{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNST_CIFAR10_AUG.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/maddy46/mlblr4a_experiments/blob/master/DNST_CIFAR10_AUG_2905.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "K70hAckqg0EA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wVIx_KIigxPV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UNHw6luQg3gc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HyZhR1RK-dZn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" I Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cauplz2iYPtZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "6c5a8b42-05cd-4fe8-a75f-e13ec9460b59"
      },
      "cell_type": "code",
      "source": [
        "!rm utils.py\n",
        "!wget https://raw.githubusercontent.com/Zahlii/colab-tf-utils/master/utils.py\n",
        "import utils\n",
        "import os\n",
        "import keras\n",
        "\n",
        "def compare(best, new):\n",
        "  return best.losses['val_acc'] < new.losses['val_acc']\n",
        "\n",
        "def path(new):\n",
        "  if new.losses['val_acc'] > 0.2:\n",
        "    return '4B_008_%s.h5' % new.losses['val_acc']\n",
        "\n",
        "callbacks = cb = [\n",
        "      utils.GDriveCheckpointer(compare,path)\n",
        "]"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-05-28 16:14:30--  https://raw.githubusercontent.com/Zahlii/colab-tf-utils/master/utils.py\r\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\r\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6935 (6.8K) [text/plain]\n",
            "Saving to: ‘utils.py’\n",
            "\n",
            "utils.py            100%[===================>]   6.77K  --.-KB/s    in 0s      \n",
            "\n",
            "2018-05-28 16:14:30 (71.5 MB/s) - ‘utils.py’ saved [6935/6935]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E-N5JGnk_jVW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "num_classes = 10\n",
        "epochs =50\n",
        "#l = 40\n",
        "num_filter = 12\n",
        "compression = 0.5\n",
        "dropout_rate = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mB7o3zu1g6eT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e90cb77a-b7f6-46c0-dded-c7c2364d2c61"
      },
      "cell_type": "code",
      "source": [
        "# Load CIFAR10 Data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "print (img_height)\n",
        "print (img_width)\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UNEhips_IZuH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a9bb9b02-84dd-471e-8b38-0d858f4aaed8"
      },
      "cell_type": "code",
      "source": [
        "print (x_train.shape[0])\n",
        "print (x_test.shape[0])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eSJeTVeo_tmf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "95c86be8-9ee6-4dc8-f3b2-456420beb6c1"
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "new_images = np.empty((50000, 32, 32, 3), dtype='uint8')\n",
        "new_test = np.empty((10000, 32, 32, 3), dtype='uint8')\n",
        "\n",
        "for image_count in range(x_train.shape[0]):\n",
        "    new_images[image_count] = cv2.resize(x_train[image_count], (32, 32))\n",
        "for image_count1 in range(x_test.shape[0]):\n",
        "    new_test[image_count1] = cv2.resize(x_test[image_count1], (32, 32))\n",
        "img_height1, img_width1, channel1 = new_images.shape[1],new_images.shape[2],new_images.shape[3]\n",
        "print (img_height1)\n",
        "print (img_width1)\n",
        "\n",
        "print('x resizing Done.')\n",
        "'''"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n",
            "x Processing Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7BgUOP3gZqnj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(zoom_range=0.2, rotation_range=20)\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ee-sge5Kg7vr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Dense Block\n",
        "def add_denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l):\n",
        "        BatchNorm = BatchNormalization()(temp)\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OOP6IPsGhBwb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def add_transition(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0RaKFpubhDIC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = Flatten()(AvgPooling)\n",
        "    output = Dense(num_classes, activation='softmax')(flat)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "anPCpQWhhGb7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a0e7ab46-3bcb-45bf-c847-2084a6855184"
      },
      "cell_type": "code",
      "source": [
        "num_filter = 16\n",
        "dropout_rate = 0.2\n",
        "l = 6\n",
        "batch_size = 32\n",
        "epochs =50\n",
        "input = Input(shape=(img_height, img_width, channel,))\n",
        "print(channel)\n",
        "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block = add_denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)\n",
        "#output = output_layer(First_Block)\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1kFh7pdxhNtT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5839
        },
        "outputId": "25e699f2-7157-4484-d0e4-6b215aad16a2"
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_216 (Conv2D)             (None, 32, 32, 16)   432         input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_216 (BatchN (None, 32, 32, 16)   64          conv2d_216[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_214 (Activation)     (None, 32, 32, 16)   0           batch_normalization_216[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_217 (Conv2D)             (None, 32, 32, 8)    1152        activation_214[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_211 (Dropout)           (None, 32, 32, 8)    0           conv2d_217[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_202 (Concatenate)   (None, 32, 32, 24)   0           conv2d_216[0][0]                 \n",
            "                                                                 dropout_211[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_217 (BatchN (None, 32, 32, 24)   96          concatenate_202[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_215 (Activation)     (None, 32, 32, 24)   0           batch_normalization_217[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_218 (Conv2D)             (None, 32, 32, 8)    1728        activation_215[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_212 (Dropout)           (None, 32, 32, 8)    0           conv2d_218[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_203 (Concatenate)   (None, 32, 32, 32)   0           concatenate_202[0][0]            \n",
            "                                                                 dropout_212[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_218 (BatchN (None, 32, 32, 32)   128         concatenate_203[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_216 (Activation)     (None, 32, 32, 32)   0           batch_normalization_218[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_219 (Conv2D)             (None, 32, 32, 8)    2304        activation_216[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_213 (Dropout)           (None, 32, 32, 8)    0           conv2d_219[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_204 (Concatenate)   (None, 32, 32, 40)   0           concatenate_203[0][0]            \n",
            "                                                                 dropout_213[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_219 (BatchN (None, 32, 32, 40)   160         concatenate_204[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_217 (Activation)     (None, 32, 32, 40)   0           batch_normalization_219[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_220 (Conv2D)             (None, 32, 32, 8)    2880        activation_217[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_214 (Dropout)           (None, 32, 32, 8)    0           conv2d_220[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_205 (Concatenate)   (None, 32, 32, 48)   0           concatenate_204[0][0]            \n",
            "                                                                 dropout_214[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_220 (BatchN (None, 32, 32, 48)   192         concatenate_205[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_218 (Activation)     (None, 32, 32, 48)   0           batch_normalization_220[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_221 (Conv2D)             (None, 32, 32, 8)    3456        activation_218[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_215 (Dropout)           (None, 32, 32, 8)    0           conv2d_221[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_206 (Concatenate)   (None, 32, 32, 56)   0           concatenate_205[0][0]            \n",
            "                                                                 dropout_215[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_221 (BatchN (None, 32, 32, 56)   224         concatenate_206[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_219 (Activation)     (None, 32, 32, 56)   0           batch_normalization_221[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_222 (Conv2D)             (None, 32, 32, 8)    4032        activation_219[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_216 (Dropout)           (None, 32, 32, 8)    0           conv2d_222[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_207 (Concatenate)   (None, 32, 32, 64)   0           concatenate_206[0][0]            \n",
            "                                                                 dropout_216[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_222 (BatchN (None, 32, 32, 64)   256         concatenate_207[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_220 (Activation)     (None, 32, 32, 64)   0           batch_normalization_222[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_223 (Conv2D)             (None, 32, 32, 8)    512         activation_220[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_217 (Dropout)           (None, 32, 32, 8)    0           conv2d_223[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_13 (AveragePo (None, 16, 16, 8)    0           dropout_217[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_223 (BatchN (None, 16, 16, 8)    32          average_pooling2d_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_221 (Activation)     (None, 16, 16, 8)    0           batch_normalization_223[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_224 (Conv2D)             (None, 16, 16, 8)    576         activation_221[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_218 (Dropout)           (None, 16, 16, 8)    0           conv2d_224[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_208 (Concatenate)   (None, 16, 16, 16)   0           average_pooling2d_13[0][0]       \n",
            "                                                                 dropout_218[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_224 (BatchN (None, 16, 16, 16)   64          concatenate_208[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_222 (Activation)     (None, 16, 16, 16)   0           batch_normalization_224[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_225 (Conv2D)             (None, 16, 16, 8)    1152        activation_222[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_219 (Dropout)           (None, 16, 16, 8)    0           conv2d_225[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_209 (Concatenate)   (None, 16, 16, 24)   0           concatenate_208[0][0]            \n",
            "                                                                 dropout_219[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_225 (BatchN (None, 16, 16, 24)   96          concatenate_209[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_223 (Activation)     (None, 16, 16, 24)   0           batch_normalization_225[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_226 (Conv2D)             (None, 16, 16, 8)    1728        activation_223[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_220 (Dropout)           (None, 16, 16, 8)    0           conv2d_226[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_210 (Concatenate)   (None, 16, 16, 32)   0           concatenate_209[0][0]            \n",
            "                                                                 dropout_220[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_226 (BatchN (None, 16, 16, 32)   128         concatenate_210[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_224 (Activation)     (None, 16, 16, 32)   0           batch_normalization_226[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_227 (Conv2D)             (None, 16, 16, 8)    2304        activation_224[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_221 (Dropout)           (None, 16, 16, 8)    0           conv2d_227[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_211 (Concatenate)   (None, 16, 16, 40)   0           concatenate_210[0][0]            \n",
            "                                                                 dropout_221[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_227 (BatchN (None, 16, 16, 40)   160         concatenate_211[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_225 (Activation)     (None, 16, 16, 40)   0           batch_normalization_227[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_228 (Conv2D)             (None, 16, 16, 8)    2880        activation_225[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_222 (Dropout)           (None, 16, 16, 8)    0           conv2d_228[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_212 (Concatenate)   (None, 16, 16, 48)   0           concatenate_211[0][0]            \n",
            "                                                                 dropout_222[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_228 (BatchN (None, 16, 16, 48)   192         concatenate_212[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_226 (Activation)     (None, 16, 16, 48)   0           batch_normalization_228[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_229 (Conv2D)             (None, 16, 16, 8)    3456        activation_226[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_223 (Dropout)           (None, 16, 16, 8)    0           conv2d_229[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_213 (Concatenate)   (None, 16, 16, 56)   0           concatenate_212[0][0]            \n",
            "                                                                 dropout_223[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_229 (BatchN (None, 16, 16, 56)   224         concatenate_213[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_227 (Activation)     (None, 16, 16, 56)   0           batch_normalization_229[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_230 (Conv2D)             (None, 16, 16, 8)    448         activation_227[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_224 (Dropout)           (None, 16, 16, 8)    0           conv2d_230[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_14 (AveragePo (None, 8, 8, 8)      0           dropout_224[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_230 (BatchN (None, 8, 8, 8)      32          average_pooling2d_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_228 (Activation)     (None, 8, 8, 8)      0           batch_normalization_230[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_231 (Conv2D)             (None, 8, 8, 8)      576         activation_228[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_225 (Dropout)           (None, 8, 8, 8)      0           conv2d_231[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_214 (Concatenate)   (None, 8, 8, 16)     0           average_pooling2d_14[0][0]       \n",
            "                                                                 dropout_225[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_231 (BatchN (None, 8, 8, 16)     64          concatenate_214[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_229 (Activation)     (None, 8, 8, 16)     0           batch_normalization_231[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_232 (Conv2D)             (None, 8, 8, 8)      1152        activation_229[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_226 (Dropout)           (None, 8, 8, 8)      0           conv2d_232[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_215 (Concatenate)   (None, 8, 8, 24)     0           concatenate_214[0][0]            \n",
            "                                                                 dropout_226[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_232 (BatchN (None, 8, 8, 24)     96          concatenate_215[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_230 (Activation)     (None, 8, 8, 24)     0           batch_normalization_232[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_233 (Conv2D)             (None, 8, 8, 8)      1728        activation_230[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_227 (Dropout)           (None, 8, 8, 8)      0           conv2d_233[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_216 (Concatenate)   (None, 8, 8, 32)     0           concatenate_215[0][0]            \n",
            "                                                                 dropout_227[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_233 (BatchN (None, 8, 8, 32)     128         concatenate_216[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_231 (Activation)     (None, 8, 8, 32)     0           batch_normalization_233[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_234 (Conv2D)             (None, 8, 8, 8)      2304        activation_231[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_228 (Dropout)           (None, 8, 8, 8)      0           conv2d_234[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_217 (Concatenate)   (None, 8, 8, 40)     0           concatenate_216[0][0]            \n",
            "                                                                 dropout_228[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_234 (BatchN (None, 8, 8, 40)     160         concatenate_217[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_232 (Activation)     (None, 8, 8, 40)     0           batch_normalization_234[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_235 (Conv2D)             (None, 8, 8, 8)      2880        activation_232[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_229 (Dropout)           (None, 8, 8, 8)      0           conv2d_235[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_218 (Concatenate)   (None, 8, 8, 48)     0           concatenate_217[0][0]            \n",
            "                                                                 dropout_229[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_235 (BatchN (None, 8, 8, 48)     192         concatenate_218[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_233 (Activation)     (None, 8, 8, 48)     0           batch_normalization_235[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_236 (Conv2D)             (None, 8, 8, 8)      3456        activation_233[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_230 (Dropout)           (None, 8, 8, 8)      0           conv2d_236[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_219 (Concatenate)   (None, 8, 8, 56)     0           concatenate_218[0][0]            \n",
            "                                                                 dropout_230[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_236 (BatchN (None, 8, 8, 56)     224         concatenate_219[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_234 (Activation)     (None, 8, 8, 56)     0           batch_normalization_236[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_237 (Conv2D)             (None, 8, 8, 8)      448         activation_234[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_231 (Dropout)           (None, 8, 8, 8)      0           conv2d_237[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_15 (AveragePo (None, 4, 4, 8)      0           dropout_231[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_237 (BatchN (None, 4, 4, 8)      32          average_pooling2d_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_235 (Activation)     (None, 4, 4, 8)      0           batch_normalization_237[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_238 (Conv2D)             (None, 4, 4, 8)      576         activation_235[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_232 (Dropout)           (None, 4, 4, 8)      0           conv2d_238[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_220 (Concatenate)   (None, 4, 4, 16)     0           average_pooling2d_15[0][0]       \n",
            "                                                                 dropout_232[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_238 (BatchN (None, 4, 4, 16)     64          concatenate_220[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_236 (Activation)     (None, 4, 4, 16)     0           batch_normalization_238[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_239 (Conv2D)             (None, 4, 4, 8)      1152        activation_236[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_233 (Dropout)           (None, 4, 4, 8)      0           conv2d_239[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_221 (Concatenate)   (None, 4, 4, 24)     0           concatenate_220[0][0]            \n",
            "                                                                 dropout_233[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_239 (BatchN (None, 4, 4, 24)     96          concatenate_221[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_237 (Activation)     (None, 4, 4, 24)     0           batch_normalization_239[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_240 (Conv2D)             (None, 4, 4, 8)      1728        activation_237[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_234 (Dropout)           (None, 4, 4, 8)      0           conv2d_240[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_222 (Concatenate)   (None, 4, 4, 32)     0           concatenate_221[0][0]            \n",
            "                                                                 dropout_234[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_240 (BatchN (None, 4, 4, 32)     128         concatenate_222[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_238 (Activation)     (None, 4, 4, 32)     0           batch_normalization_240[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_241 (Conv2D)             (None, 4, 4, 8)      2304        activation_238[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_235 (Dropout)           (None, 4, 4, 8)      0           conv2d_241[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_223 (Concatenate)   (None, 4, 4, 40)     0           concatenate_222[0][0]            \n",
            "                                                                 dropout_235[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_241 (BatchN (None, 4, 4, 40)     160         concatenate_223[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_239 (Activation)     (None, 4, 4, 40)     0           batch_normalization_241[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_242 (Conv2D)             (None, 4, 4, 8)      2880        activation_239[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_236 (Dropout)           (None, 4, 4, 8)      0           conv2d_242[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_224 (Concatenate)   (None, 4, 4, 48)     0           concatenate_223[0][0]            \n",
            "                                                                 dropout_236[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_242 (BatchN (None, 4, 4, 48)     192         concatenate_224[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_240 (Activation)     (None, 4, 4, 48)     0           batch_normalization_242[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_243 (Conv2D)             (None, 4, 4, 8)      3456        activation_240[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_237 (Dropout)           (None, 4, 4, 8)      0           conv2d_243[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_225 (Concatenate)   (None, 4, 4, 56)     0           concatenate_224[0][0]            \n",
            "                                                                 dropout_237[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_243 (BatchN (None, 4, 4, 56)     224         concatenate_225[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_241 (Activation)     (None, 4, 4, 56)     0           batch_normalization_243[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_16 (AveragePo (None, 2, 2, 56)     0           activation_241[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 224)          0           average_pooling2d_16[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 10)           2250        flatten_4[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 59,738\n",
            "Trainable params: 57,834\n",
            "Non-trainable params: 1,904\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b4XOsW3ahSkL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# determine Loss function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "crhGk7kEhXAz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2209
        },
        "outputId": "09cd8d04-2327-4657-9640-5ee1861dca97"
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test),callbacks=cb)\n",
        "                    '''\n",
        "\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size), epochs=epochs, \n",
        "                    verbose=1, validation_data=(x_test\n",
        "                                                , y_test),\n",
        "                    steps_per_epoch=len(x_train)/batch_size, callbacks=cb)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1562/1562 [============================>.] - ETA: 0s - loss: 1.6986 - acc: 0.3719"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1563/1562 [==============================] - 2242s 1s/step - loss: 1.6985 - acc: 0.3719 - val_loss: 1.9348 - val_acc: 0.3780\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploading file 4B_008_0.378.h5 to folder Colab Notebooks: 100%|██████████| 100/100 [00:01<00:00, 98.91it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "1562/1562 [============================>.] - ETA: 0s - loss: 1.4333 - acc: 0.4804"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1563/1562 [==============================] - 2218s 1s/step - loss: 1.4332 - acc: 0.4805 - val_loss: 1.4034 - val_acc: 0.5096\n",
            "Removing old cloud file 4B_008_0.378.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploading file 4B_008_0.5096.h5 to folder Colab Notebooks: 100%|██████████| 100/100 [00:00<00:00, 114.66it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/50\n",
            "1562/1562 [============================>.] - ETA: 0s - loss: 1.3117 - acc: 0.5239"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1563/1562 [==============================] - 2198s 1s/step - loss: 1.3116 - acc: 0.5240 - val_loss: 1.4462 - val_acc: 0.5108\n",
            "Removing old cloud file 4B_008_0.5096.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploading file 4B_008_0.5108.h5 to folder Colab Notebooks: 100%|██████████| 100/100 [00:00<00:00, 111.97it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/50\n",
            "1562/1562 [============================>.] - ETA: 0s - loss: 1.2225 - acc: 0.5570"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1563/1562 [==============================] - 2213s 1s/step - loss: 1.2223 - acc: 0.5570 - val_loss: 1.4005 - val_acc: 0.5490\n",
            "Removing old cloud file 4B_008_0.5108.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploading file 4B_008_0.549.h5 to folder Colab Notebooks: 100%|██████████| 100/100 [00:00<00:00, 122.08it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/50\n",
            "1562/1562 [============================>.] - ETA: 0s - loss: 1.1731 - acc: 0.5772"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1563/1562 [==============================] - 2238s 1s/step - loss: 1.1729 - acc: 0.5774 - val_loss: 1.2486 - val_acc: 0.5904\n",
            "Removing old cloud file 4B_008_0.549.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploading file 4B_008_0.5904.h5 to folder Colab Notebooks: 100%|██████████| 100/100 [00:00<00:00, 110.42it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/50\n",
            "1562/1562 [============================>.] - ETA: 0s - loss: 1.1248 - acc: 0.5958"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1563/1562 [==============================] - 2212s 1s/step - loss: 1.1248 - acc: 0.5958 - val_loss: 1.4771 - val_acc: 0.5346\n",
            "No improvement.\n",
            "Epoch 7/50\n",
            " 313/1562 [=====>........................] - ETA: 27:32 - loss: 1.0794 - acc: 0.6130"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [============================>.] - ETA: 0s - loss: 1.0900 - acc: 0.6089"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1563/1562 [==============================] - 2211s 1s/step - loss: 1.0898 - acc: 0.6090 - val_loss: 1.1456 - val_acc: 0.6333\n",
            "Removing old cloud file 4B_008_0.5904.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploading file 4B_008_0.6333.h5 to folder Colab Notebooks: 100%|██████████| 100/100 [00:00<00:00, 133.60it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/50\n",
            "1562/1562 [============================>.] - ETA: 0s - loss: 1.0599 - acc: 0.6211"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1563/1562 [==============================] - 2217s 1s/step - loss: 1.0597 - acc: 0.6212 - val_loss: 1.4022 - val_acc: 0.5690\n",
            "No improvement.\n",
            "Epoch 9/50\n",
            " 313/1562 [=====>........................] - ETA: 27:42 - loss: 1.0482 - acc: 0.6230"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [============================>.] - ETA: 0s - loss: 1.0380 - acc: 0.6294"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1563/1562 [==============================] - 2226s 1s/step - loss: 1.0379 - acc: 0.6295 - val_loss: 1.3462 - val_acc: 0.5943\n",
            "No improvement.\n",
            "Epoch 10/50\n",
            " 312/1562 [====>.........................] - ETA: 27:45 - loss: 1.0052 - acc: 0.6456"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [============================>.] - ETA: 0s - loss: 1.0123 - acc: 0.6408"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1563/1562 [==============================] - 2228s 1s/step - loss: 1.0123 - acc: 0.6408 - val_loss: 1.4139 - val_acc: 0.5768\n",
            "No improvement.\n",
            "Epoch 11/50\n",
            " 312/1562 [====>.........................] - ETA: 27:36 - loss: 0.9946 - acc: 0.6416"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 761/1562 [=============>................] - ETA: 17:43 - loss: 0.9987 - acc: 0.6410"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-df7dcbbae908>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                     verbose=1, validation_data=(x_test\n\u001b[1;32m     11\u001b[0m                                                 , y_test),\n\u001b[0;32m---> 12\u001b[0;31m                     steps_per_epoch=len(x_train)/batch_size, callbacks=cb)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2228\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2229\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2230\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "l_y5QoBdE4ls",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "702972a6-edf4-4f9f-cbef-9a7ea4297521"
      },
      "cell_type": "code",
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "model.save_weights(\"saved_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}